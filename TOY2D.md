# Toy 2D experiments

The toy 2D experiments presented in Figure 3 in our [paper](https://arxiv.org/abs/1906.01916) can be
re-created using the `toy2d_train.py` program.

#### Supervised baseline

Note that only 25 epochs are needed to converge.

```shell script
python toy2d_train.py --job_desc=cluster_sup --dataset=img:data/toy2d/curve_mask_v3.png --sup_path=data/toy2d/curve_mask_v3_35.pkl --region_erode_radius=35 --num_epochs=25 --cons_weight=0.0 --save_output
```


#### Semi-supervised with low-density region separating classes

```shell script
python toy2d_train.py --job_desc=cluster_semisup --exp=img:data/toy2d/curve_mask_v3.png --sup_path=data/toy2d/curve_mask_v3_35.pkl --region_erode_radius=35 --num_epochs=100 --save_output
```

#### Continuous distribution, no low-density regions

```shell script
python toy2d_train.py --job_desc=continuous_semisup_run01 --dataset=img:data/toy2d/curve_mask_v3.png --sup_path=data/toy2d/curve_mask_v3_35.pkl --region_erode_radius=0 --norm_layer=none --cons_no_dropout --cons_loss_fn=logits_var --cons_weight=1.0 --perturb_noise_std=30.0 --dist_contour_range=4.0 --num_epochs=100 --render_pred=class --save_output
```

Note that we admit that it can take several runs to get an output that is as close to the true
class boundary as seen in the paper. This is only a toy example though.
An explanation of the command line arguments used here:
- `--region_erode_radius=0` to remove the low-density region, making the distribution continuous
- `--norm_layer=none` no batch norm
- `--cons_no_dropout` no dropout when computing consistency loss
- `--cons_loss_fn=logits_var` compute squared diff between predicted logits, rather than probabilities
- `--cons_weight=1.0` consistency loss weight of 1 when using `logits_var`
- `--perturb_noise_std=30.0` increase the size of the perturbation from `6` to `30`
- `--dist_contour_range=4.0` this contrains perturbations to lie on distance map contours


### Command line options

- `--job_desc`: provide a job description/name. For example, running the `toy2d_train.py`
    with `--job_desc=test_a_1` program will save its log file to `results/toy2d_train/log_test_a_1.txt`
    and output images will be saved to the directory `results/toy2d_train/test_a_1`.
- `--dataset` *[default=spiral]*: the dataset to use
    - `spiral`: two-arm spiral dataset with each arm having a different class
    - `img:<path>` to generate a 2-class dataset from an image (this was used
        for the figures in the paper; `--dataset=img:data/toy2d/curve_mask_v2.png`).
        The image is converted to greyscale and any pixel whose value
        is greater than half-grey is assigned the class of 1, with darker pixels assigned the class 0.
        The regions are then eroded by `region_erode_radius` pixels; see the `--region_erode_radius`
        option below. One sample is then created for each pixel. Their positions are randomized using
        additive Gaussian noise with a std-dev of `img_noise_std` (see `--img_noise_std` option below).
- `--region_erode_radius` *[default=35]*: the amount of binary erosion applied to the contiguous class regions
    generated by an image dataset. This is used to create low density regions between the classes.
- `--img_noise_std` *[default=2.0]*: the amount of noise to apply to the locations of the samples generated
    by an image dataset
- `--n_sup` *[default=100]*: the number of supervised samples to use during training. These will be randomly
    selected from the training set, using the random seed provided using `--seed` to initialise the
    RNG.
- `--balance_classes` *[default=False]*: if True select an equal number of supervised samples for each
    class. Samples will be chosen randomly.
- `--seed` *[default=12345]*: the seed used to initialise the RNG used to select supervised samples
- `--sup_path`: a path from which to load a Python pickle file that gives the supervised samples.
    Useful to ensure consistent choice of supervised samples (for the figures in the paper
`--sup_path=data/toy2d/curve_mask_v3_35.pkl`)
- `--model` *[default=mean_teacher]*: the model to use
    - `mean_teacher`: Mean Teacher model
    - `pi`: Pi-model
    - `pi_onebatch`: Pi-model where supervised and unsupervised samples are concatenated into one batch
- `--n_hidden` *[default=3]*: number of hidden layers in MLP model
- `--hidden_size` *[default=512]*: number of units in each hidden layer
- `--hidden_act` *[default=relu]*: activation function
    - `relu`: ReLU
    - `lrelu`: Leaky ReLU with alpha=0.01
- `--perturb_noise_std` *[default=6.0]*: the std-dev of the perturbation used to drive consistency
    regularization, in pixels
- `--dist_contour_range` *[default=0]*: if non-zero, consistency loss will only be applied when
    the perturbation applied to an unsupervised sample changes the distance to the class boundary
    by less than this amount. Note that this *only* works with image datasets
- `--conf_thresh` *[default=0.97]*: confidence threshold
- `--conf_avg` *[default=False]*: if True, average the confidence threshold values across each batch
- `--cons_weight` *[default=10]*: the consistency loss weigting factor
- `--cons_loss_fn` *[default=var]*: consistency loss function:
    - `var`: squared error between predicted probabilities
    - `bce`: binary cross entropy, using teacher predictions as target
    - `logits_var`: squared error between predicted pre-softmax logits
- `--cons_no_dropout` *[default=False]*: if True, disable dropout when computing consistency loss
- `--learning_rate` *[default=2e-4]*: set learning rate
- `--teacher_alpha` *[default=0.99]*: EMA alpha used to update teacher network when using the mean teacher model 
- `--num_epochs` *[default=100]*: number of epochs to train for
- `--batch_size` *[default=512]*: the mini-batch size 
- `--render_cons_grad` *[default=False]*: if True, render the magnitude of the gradient of the consistency
    loss with respect to the logits generated by the network. Will be rendered in red. Indicates
    which samples are contributing most of the consistency loss learning.
- `--render_pred` *[default=prob]*: how to render the predictions/decision function
    - `prob`: render soft probability predictions
    - `class`: render hard class predictions
- `--device` *[default=cuda:0]*: the torch device to use
- `--save_output` *[default=False]*: if False, render the output to a window, if True save the
    output to PNG files in `results/toy2d_train/<job_desc>/epoch_<epoch>.png`


 