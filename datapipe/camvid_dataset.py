import os
import settings
import numpy as np
from datapipe import seg_data


class CamVidAccessor (seg_data.SegAccessor):
    def __len__(self):
        return len(self.ds.x_names)

    def get_image_pil(self, sample_i):
        return self.ds.get_pil_image(self.ds.x_names[sample_i])

    def get_labels_arr(self, sample_i):
        pil_img = self.ds.get_pil_image(self.ds.y_names[sample_i])
        y = np.array(pil_img)
        y[y==11] = 255
        return y


class CamVidDataSource (seg_data.ZipDataSource):
    def __init__(self, n_val, val_rng, trainval_perm):
        super(CamVidDataSource, self).__init__(
            settings.get_data_path(
                config_name='camvid',
                dnnlib_template=os.path.join(
                    '<DATASETS>', 'research', 'gfrench', 'camvid', 'CamVidData.zip'
            ))
        )

        sample_names = set()
        sample_name_to_dir_name = {}

        for filename in self.zip_file.namelist():
            dir_name, sample_name = os.path.split(filename)

            if not dir_name.endswith('annot') and os.path.splitext(sample_name)[1].lower() == '.png':
                sample_names.add(sample_name)
                sample_name_to_dir_name[sample_name] = dir_name
        sample_names = list(sample_names)
        sample_names.sort()

        self.x_names = [sample_name_to_dir_name[name] + '/' + name for name in sample_names]
        self.y_names = [sample_name_to_dir_name[name] + 'annot/' + name for name in sample_names]
        self.sample_names = sample_names

        self.train_ndx = np.array([i for i in range(len(self.x_names))
                                   if os.path.split(self.x_names[i])[0].endswith('train')])
        self.val_ndx = np.array([i for i in range(len(self.x_names))
                                 if os.path.split(self.x_names[i])[0].endswith('val')])
        self.test_ndx = np.array([i for i in range(len(self.x_names))
                                  if os.path.split(self.x_names[i])[0].endswith('test')])

        if n_val > 0 and n_val < len(self.val_ndx):
            self.val_ndx = self.val_ndx[val_rng.permutation(len(self.val_ndx))[:n_val]]

        # weights when using median frequency balancing used in SegNet paper
        # https://arxiv.org/pdf/1511.00561.pdf
        # The numbers were generated by https://github.com/yandex/segnet-torch/blob/master/datasets/camvid-gen.lua
        self.class_weights = np.array([0.58872014284134, 0.51052379608154, 2.6966278553009, 0.45021694898605, 1.1785038709641,
                0.77028578519821, 2.4782588481903, 2.5273461341858, 1.0122526884079, 3.2375309467316,
                4.1312313079834, 0])

        self.class_names = ['Sky', 'Building', 'Pole', 'Road', 'Pavement', 'Tree', 'SignSymbol', 'Fence',
                            'Car', 'Pedestrian', 'Bicyclist', 'void']

        self.num_classes_all = len(self.class_names)
        self.num_classes = len(self.class_names) - 1


    def dataset(self, labels, mask, xf, transforms=None, pipeline_type='cv', include_indices=False):
        return CamVidAccessor(self, labels, mask, xf, transforms=transforms, pipeline_type=pipeline_type,
                              include_indices=include_indices)


    def get_mean_std(self):
        # For now:
        return (np.array([0.41189489566336, 0.4251328133025, 0.4326707089857]),
                np.array([0.27413549931506, 0.28506257482912, 0.28284674400252]))
